apiVersion: batch/v1
kind: Job
metadata:
  name: loading-transf-data
  namespace: spark-kubernetes
spec:
  template:
    spec:
      containers:
      - name: loading-transf-data
        image: loading_transf_data:1.0
        imagePullPolicy: Never
        command: [
          "/bin/bash",
          "-c",
          "/opt/spark/bin/spark-submit \
          --master k8s://https://kind-control-plane:6443 \ 
          --deploy-mode cluster \
          --name loading-transf-data \
          --class com.cognira.loadingTransfData.Main \
          --driver-java-options -Dlog4j.configuration=file:/app/src/main/resources/log4j.properties \
          --conf spark.cassandra.auth.username=cassandra \
          --conf spark.cassandra.auth.password=cassandra \
          --conf spark.executor.instances=3 \
          --conf spark.kubernetes.authenticate.driver.serviceAccountName=spark \
          --conf spark.kubernetes.namespace=spark-kubernetes \
          --conf spark.kubernetes.container.image=loading_transf_data:1.0 \
          --conf spark.kubernetes.container.image.pullPolicy=Never \
          --conf spark.driver.host=$(hostname -i) \
          --conf spark.driver.pod.name=$(hostname) \
          --conf spark.dynamicAllocation.shuffleTracking.enabled=false \
          --conf spark.dynamicAllocation.enabled=false \
          --conf spark.kubernetes.executor.deleteOnTermination=true \
          --conf spark.kubernetes.driver.pod.name=loading-transf-data-driver \
          --conf spark.kubernetes.driver.volumes.persistentVolumeClaim.metrics-pvc.options.claimName=metrics-pvc \
          --conf spark.kubernetes.driver.volumes.persistentVolumeClaim.metrics-pvc.mount.path=/opt/transformations \
          --conf spark.kubernetes.executor.volumes.persistentVolumeClaim.metrics-pvc.options.claimName=metrics-pvc \
          --conf spark.kubernetes.executor.volumes.persistentVolumeClaim.metrics-pvc.mount.path=/opt/transformations \
          local:///opt/target/scala-2.12/loading_transf_data_2.12-0.1.jar"
        ]
      restartPolicy: Never
      serviceAccountName: spark
  backoffLimit: 2
